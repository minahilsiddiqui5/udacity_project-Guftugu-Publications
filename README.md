# Guftugu Publications

## Project Objective
This project aims to collect and clean book data from two different sources: the Guftugu Publications website and Kaggle datasets. The goal is to create a comprehensive dataset of books for further analysis.

## Data Sources
1. **Guftugu Publications Website**: I scraped book data from the Guftugu Publications website using web scraping techniques. The data includes book titles, authors, and other relevant information.

2. **Kaggle Datasets**: Additional book data was obtained from Kaggle datasets, which provided a wide range of book-related information, including user ratings, reviews, and more.

## Dependencies
To run the data wrangling code and analysis, the following Python libraries and packages were used:
- `pandas` for data manipulation
- `beautifulsoup4` for web scraping
- Other standard Python libraries for data cleaning and analysis

## Data Wrangling Steps
The data wrangling process involved the following steps:
1. Web scraping the Guftugu Publications website to extract book data.
2. Data cleaning, including handling missing values, removing duplicates, and standardizing data formats.
3. Exploratory data analysis (EDA) to gain insights into the combined dataset.
4. Saving the cleaned dataset for further analysis and visualization.

